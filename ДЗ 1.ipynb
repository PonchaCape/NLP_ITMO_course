{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd57c8a6",
   "metadata": {},
   "source": [
    "# Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088b02c9",
   "metadata": {},
   "source": [
    "### Задание 1 - 30 баллов\n",
    "\n",
    "- Загрузить набор данных [Spam Or Not Spam](https://www.kaggle.com/datasets/ozlerhakan/spam-or-not-spam-dataset)\n",
    "- Попробовать и сравнить различные способы векторизации:\n",
    "  - `sklearn.feature_extraction.text.CountVectorizer`\n",
    "  - `sklearn.feature_extraction.text.TfidfVectorizer`\n",
    "- Обучить на полученных векторах модели, с использованием кросс-валидации и подбором гиперпараметров:\n",
    "  - `sklearn.tree.DecisionTreeClassifier`\n",
    "  - `sklearn.linear_model.LogisticRegression`\n",
    "  - Naive Bayes\n",
    "- Сравнить качество обученных моделей на отложенной выборке\n",
    "\n",
    "Перед отправкой необходимо обеспечить воспроизводимость решения: зафиксированы random_state, ноутбук воспроизводится от начала до конца без ошибок\n",
    "\n",
    "#### Дата выдачи\n",
    "\n",
    "09.10.2023\n",
    "\n",
    "#### Мягкий дедлайн\n",
    "\n",
    "17.10.2023 20:00 мск\n",
    "\n",
    "#### Критерии оценки\n",
    "\n",
    "- Датасет Spam Or Not Spam загружен - **2 балла**\n",
    "- Реализована релевантная задаче предобработка текстов - **3 балла**\n",
    "- Все модели векторизации обучены - **5 баллов**\t\n",
    "- Все необходимые модели классификации обучены - **5 баллов**\n",
    "- Модели классификации обучены с использованием механизма кросс-валидации - **5 баллов**\n",
    "- Для всех моделей классификации подобраны гиперпараметры - **5 баллов**\n",
    "- Произведено сравнение качества полученных моделей - **5 баллов**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6566bc",
   "metadata": {},
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c51d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import lightgbm\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0ec3862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    return \n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e46c3d",
   "metadata": {},
   "source": [
    "# Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32a7d54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>martin a posted tassos papadopoulos the greek ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>man threatens explosion in moscow thursday aug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>klez the virus that won t die already the most...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in adding cream to spaghetti carbonara which ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email  label\n",
       "0   date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...      0\n",
       "1  martin a posted tassos papadopoulos the greek ...      0\n",
       "2  man threatens explosion in moscow thursday aug...      0\n",
       "3  klez the virus that won t die already the most...      0\n",
       "4   in adding cream to spaghetti carbonara which ...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('spam_or_not_spam.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "332f420d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   email   2999 non-null   object\n",
      " 1   label   3000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bcd078a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2966</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     email  label\n",
       "2966   NaN      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.email.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d51f5161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2500\n",
       "1     499\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afceb6b",
   "metadata": {},
   "source": [
    "## Предобработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba598291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       date wed number aug number number number numbe...\n",
       "1       martin a posted tassos papadopoulos the greek ...\n",
       "2       man threatens explosion in moscow thursday aug...\n",
       "3       klez the virus that won t die already the most...\n",
       "4       in adding cream to spaghetti carbonara which h...\n",
       "                              ...                        \n",
       "2995    abc s good morning america ranks it the number...\n",
       "2996    hyperlink hyperlink hyperlink let mortgage len...\n",
       "2997    thank you for shopping with us gifts for all o...\n",
       "2998    the famous ebay marketing e course learn to se...\n",
       "2999    hello this is chinese traditional number o num...\n",
       "Name: email, Length: 2999, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data.email\n",
    "texts_preproccessed = texts.str.lower()\n",
    "texts_preproccessed = texts_preproccessed.apply(lambda x: re.sub(r'[^a-z ]', '', x))\n",
    "texts_preproccessed = texts_preproccessed.str.replace(r'[ ]+', r' ', regex=True).str.strip()\n",
    "texts_preproccessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b696126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "806     url\n",
       "2806       \n",
       "2828       \n",
       "Name: email, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broken_texts = texts_preproccessed[texts_preproccessed.apply(len)<20]\n",
    "broken_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "442ce696",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_filtered = texts_preproccessed[~texts_preproccessed.index.isin(broken_texts.index)]\n",
    "labels_filtered = data.label[texts_filtered.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11092e05",
   "metadata": {},
   "source": [
    "# Векторизация текста и обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "21286e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()\n",
    "tf_idf = TfidfVectorizer()\n",
    "\n",
    "log_reg = LogisticRegression(random_state=seed)\n",
    "tree = DecisionTreeClassifier(random_state=seed)\n",
    "bayes = GaussianNB()\n",
    "\n",
    "\n",
    "models = [log_reg, tree]\n",
    "vectorizers = [count_vec, tf_idf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e1a6f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna_log = optuna.integration.OptunaSearchCV(\n",
    "    log_reg,\n",
    "    {\"C\": optuna.distributions.FloatDistribution(1e-10, 1e10, log=True),\n",
    "     \"penalty\":['l1', 'l2']},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ef61d421",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts_filtered,\n",
    "    labels_filtered,\n",
    "    test_size=0.2,\n",
    "    random_state=seed,\n",
    "    stratify=labels_filtered,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "34270d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Комбинация CountVectorizer(), LogisticRegression(random_state=42): \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       500\n",
      "           1       1.00      0.93      0.96       100\n",
      "\n",
      "    accuracy                           0.99       600\n",
      "   macro avg       0.99      0.97      0.98       600\n",
      "weighted avg       0.99      0.99      0.99       600\n",
      "\n",
      "\n",
      " -------------------------------\n",
      "Комбинация CountVectorizer(), DecisionTreeClassifier(random_state=42): \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       500\n",
      "           1       0.91      0.86      0.88       100\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.94      0.92      0.93       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "\n",
      " -------------------------------\n",
      "Комбинация TfidfVectorizer(), LogisticRegression(random_state=42): \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       500\n",
      "           1       0.99      0.80      0.88       100\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.97      0.90      0.93       600\n",
      "weighted avg       0.97      0.96      0.96       600\n",
      "\n",
      "\n",
      " -------------------------------\n",
      "Комбинация TfidfVectorizer(), DecisionTreeClassifier(random_state=42): \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       500\n",
      "           1       0.90      0.89      0.89       100\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.94      0.94      0.94       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "\n",
      " -------------------------------\n"
     ]
    }
   ],
   "source": [
    "for vectorizer in vectorizers:\n",
    "    for model in models:\n",
    "        pipe = Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            ('model', model),\n",
    "        ])\n",
    "        pipe.fit(X_train, y_train)\n",
    "        print(f'Комбинация {vectorizer}, {model}: \\n',\n",
    "              classification_report(y_test, pipe.predict(X_test)))\n",
    "        print('\\n', '-------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8940c476",
   "metadata": {},
   "source": [
    "#### Байес + count_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab9a7a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       500\n",
      "           1       0.95      0.74      0.83       100\n",
      "\n",
      "    accuracy                           0.95       600\n",
      "   macro avg       0.95      0.87      0.90       600\n",
      "weighted avg       0.95      0.95      0.95       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_transformed = count_vec.fit_transform(X_train)\n",
    "bayes.fit(X_train_transformed.A, y_train)\n",
    "print(classification_report(y_test, bayes.predict(count_vec.transform(X_test).A)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b40852",
   "metadata": {},
   "source": [
    "#### Байес + tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4ae844fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97       500\n",
      "           1       0.93      0.71      0.81       100\n",
      "\n",
      "    accuracy                           0.94       600\n",
      "   macro avg       0.94      0.85      0.89       600\n",
      "weighted avg       0.94      0.94      0.94       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_transformed = tf_idf.fit_transform(X_train)\n",
    "bayes.fit(X_train_transformed.A, y_train)\n",
    "print(classification_report(y_test, bayes.predict(tf_idf.transform(X_test).A)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e3bd10",
   "metadata": {},
   "source": [
    "Если брать векторизацию и модель без регулировки гиперпараметров, то наилучшее значение показала логистическая регрессия с более простым CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bbbe51",
   "metadata": {},
   "source": [
    "#### Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3012922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = lightgbm.LGBMClassifier(random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e36e591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 399, number of negative: 2000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 63591\n",
      "[LightGBM] [Info] Number of data points in the train set: 2399, number of used features: 2135\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166319 -> initscore=-1.611941\n",
      "[LightGBM] [Info] Start training from score -1.611941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       500\n",
      "           1       0.98      0.95      0.96       100\n",
      "\n",
      "    accuracy                           0.99       600\n",
      "   macro avg       0.98      0.97      0.98       600\n",
      "weighted avg       0.99      0.99      0.99       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_transformed = tf_idf.fit_transform(X_train)\n",
    "lgb.fit(X_train_transformed, y_train)\n",
    "print(classification_report(y_test, lgb.predict(tf_idf.transform(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d681cd6",
   "metadata": {},
   "source": [
    "# Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e8b68c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna_log = optuna.integration.OptunaSearchCV(\n",
    "    log_reg,\n",
    "    {\"C\": optuna.distributions.FloatDistribution(1e-10, 1e10, log=True),\n",
    "     \"penalty\":optuna.distributions.CategoricalDistribution(['l1', 'l2'])},\n",
    ")\n",
    "\n",
    "optuna_tree = optuna.integration.OptunaSearchCV(\n",
    "    tree,\n",
    "    {}\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8a199eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-25 17:32:21,336] A new study created in memory with name: no-name-ffcfb07d-64db-4d12-b51d-7f894d832895\n",
      "[I 2023-10-25 17:32:27,871] Trial 0 finished with value: 0.9749591162143354 and parameters: {'C': 0.01592499032163402, 'penalty': 'l2'}. Best is trial 0 with value: 0.9749591162143354.\n",
      "[W 2023-10-25 17:32:27,906] Trial 1 failed with parameters: {'C': 0.00020701025948382555, 'penalty': 'l1'} because of the following error: The value nan is not acceptable.\n",
      "[W 2023-10-25 17:32:27,908] Trial 1 failed with value nan.\n",
      "[W 2023-10-25 17:32:27,942] Trial 2 failed with parameters: {'C': 0.001043822605696029, 'penalty': 'l1'} because of the following error: The value nan is not acceptable.\n",
      "[W 2023-10-25 17:32:27,943] Trial 2 failed with value nan.\n",
      "[W 2023-10-25 17:32:27,990] Trial 3 failed with parameters: {'C': 903.2994939650298, 'penalty': 'l1'} because of the following error: The value nan is not acceptable.\n",
      "[W 2023-10-25 17:32:27,992] Trial 3 failed with value nan.\n",
      "[W 2023-10-25 17:32:28,032] Trial 4 failed with parameters: {'C': 3.64483915542939e-07, 'penalty': 'l1'} because of the following error: The value nan is not acceptable.\n",
      "[W 2023-10-25 17:32:28,035] Trial 4 failed with value nan.\n",
      "[I 2023-10-25 17:32:35,527] Trial 5 finished with value: 0.9899826026443981 and parameters: {'C': 2170.59071182029, 'penalty': 'l2'}. Best is trial 5 with value: 0.9899826026443981.\n",
      "[W 2023-10-25 17:32:35,575] Trial 6 failed with parameters: {'C': 6.605412042556953e-10, 'penalty': 'l1'} because of the following error: The value nan is not acceptable.\n",
      "[W 2023-10-25 17:32:35,576] Trial 6 failed with value nan.\n",
      "[W 2023-10-25 17:32:35,615] Trial 7 failed with parameters: {'C': 1.2306685510428558e-10, 'penalty': 'l1'} because of the following error: The value nan is not acceptable.\n",
      "[W 2023-10-25 17:32:35,615] Trial 7 failed with value nan.\n",
      "[W 2023-10-25 17:32:35,660] Trial 8 failed with parameters: {'C': 9.401497405934904e-06, 'penalty': 'l1'} because of the following error: The value nan is not acceptable.\n",
      "[W 2023-10-25 17:32:35,660] Trial 8 failed with value nan.\n",
      "[I 2023-10-25 17:32:43,136] Trial 9 finished with value: 0.9904001391788448 and parameters: {'C': 28.221638150339164, 'penalty': 'l2'}. Best is trial 9 with value: 0.9904001391788448.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OptunaSearchCV(estimator=LogisticRegression(random_state=42), n_jobs=1,\n",
       "               param_distributions={'C': FloatDistribution(high=10000000000.0, log=True, low=1e-10, step=None),\n",
       "                                    'penalty': CategoricalDistribution(choices=('l1', 'l2'))})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna_log.fit(count_vec.fit_transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aa12400a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       500\n",
      "           1       1.00      0.97      0.98       100\n",
      "\n",
      "    accuracy                           0.99       600\n",
      "   macro avg       1.00      0.98      0.99       600\n",
      "weighted avg       1.00      0.99      0.99       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, optuna_log.predict(count_vec.transform(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca1901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna lgb ="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddf311f",
   "metadata": {},
   "source": [
    "# Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74912a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    ")\n",
    "from datasets import ClassLabel, Dataset, Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c75deac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7cdb05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0a03de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(texts):\n",
    "    return tokenizer(texts[\"email\"], padding=\"max_length\", truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a1cc9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639b2a94da894d95b46333c2b6f9361d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stringifying the column:   0%|          | 0/2999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ceaebdf57d494fa0feedf2c4cafeed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/2999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8e335278e5457a87d4d00611c09f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['email', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2099\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['email', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 900\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_dataset = Dataset.from_pandas(data, split='train')\n",
    "bert_dataset = bert_dataset.class_encode_column(\"label\")\n",
    "\n",
    "bert_dataset = bert_dataset.map(tokenize, batched=True)\n",
    "bert_dataset = bert_dataset.train_test_split(test_size=0.3)\n",
    "bert_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87cbf2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    return f1_score(label, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ae50000",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"bert\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\"\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=training_args, \n",
    "    train_dataset=bert_dataset['train'], \n",
    "    eval_dataset=bert_dataset['test'],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=f1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7c36f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9839e72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
